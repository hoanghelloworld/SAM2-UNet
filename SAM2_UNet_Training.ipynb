{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0070d9c4",
   "metadata": {},
   "source": [
    "# SAM2-UNet Training and Prediction\n",
    "\n",
    "This notebook guides through:\n",
    "1. Training the SAM2-UNet model for image segmentation\n",
    "2. Evaluating the model on validation data\n",
    "3. Making predictions on test data for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as opt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Import our modules\n",
    "from dataset import FullDataset, TestDataset\n",
    "from SAM2UNet import SAM2UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac2a1f",
   "metadata": {},
   "source": [
    "## 1. Configuration Settings\n",
    "\n",
    "Let's set up the configuration parameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Model parameters\n",
    "    hiera_path = \"path/to/sam2/pretrained/hiera\"  # Change this to your sam2 pretrained hiera path\n",
    "    \n",
    "    # Data paths - update these to your data locations\n",
    "    train_image_path = \"train/images/\"\n",
    "    train_mask_path = \"train/masks/\"\n",
    "    val_image_path = \"val_images/\"\n",
    "    val_mask_path = \"val_masks/\"\n",
    "    test_image_path = \"test/images/\"\n",
    "    \n",
    "    # Output paths\n",
    "    save_path = \"checkpoints/\"\n",
    "    prediction_output_path = \"predictions/\"\n",
    "    \n",
    "    # Training parameters\n",
    "    epoch = 20\n",
    "    lr = 0.001\n",
    "    batch_size = 8\n",
    "    weight_decay = 5e-4\n",
    "    image_size = 352\n",
    "    \n",
    "    # Seed for reproducibility\n",
    "    seed = 1024\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(config.save_path, exist_ok=True)\n",
    "os.makedirs(config.prediction_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13175fe",
   "metadata": {},
   "source": [
    "## 2. Set Random Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfd7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=1024):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c050c3",
   "metadata": {},
   "source": [
    "## 3. Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_loss(pred, mask):\n",
    "    \"\"\"\n",
    "    Combined weighted BCE and weighted IoU loss for better segmentation results\n",
    "    \"\"\"\n",
    "    weit = 1 + 5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n",
    "    wbce = F.binary_cross_entropy_with_logits(pred, mask, reduction='none')\n",
    "    wbce = (weit*wbce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))\n",
    "    \n",
    "    pred = torch.sigmoid(pred)\n",
    "    inter = ((pred * mask)*weit).sum(dim=(2, 3))\n",
    "    union = ((pred + mask)*weit).sum(dim=(2, 3))\n",
    "    wiou = 1 - (inter + 1)/(union - inter+1)\n",
    "    \n",
    "    return (wbce + wiou).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f217f2",
   "metadata": {},
   "source": [
    "## 4. Prepare Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ead18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "train_dataset = FullDataset(\n",
    "    config.train_image_path, \n",
    "    config.train_mask_path, \n",
    "    config.image_size, \n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "val_dataset = FullDataset(\n",
    "    config.val_image_path, \n",
    "    config.val_mask_path, \n",
    "    config.image_size, \n",
    "    mode='val'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbf79c",
   "metadata": {},
   "source": [
    "## 5. Initialize Model, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SAM2UNet(config.hiera_path)\n",
    "model = model.to(config.device)\n",
    "\n",
    "# Setup optimizer and learning rate scheduler\n",
    "optimizer = opt.AdamW(\n",
    "    [{\"params\": model.parameters(), \"initial_lr\": config.lr}], \n",
    "    lr=config.lr, \n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    config.epoch, \n",
    "    eta_min=1.0e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85223aad",
   "metadata": {},
   "source": [
    "## 6. Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    dice_score = 0.0\n",
    "    iou_score = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "            x = batch['image'].to(device)\n",
    "            target = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred0, pred1, pred2 = model(x)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss0 = structure_loss(pred0, target)\n",
    "            loss1 = structure_loss(pred1, target)\n",
    "            loss2 = structure_loss(pred2, target)\n",
    "            loss = loss0 + loss1 + loss2\n",
    "            \n",
    "            # Accumulate validation loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics using final prediction\n",
    "            pred = torch.sigmoid(pred0) > 0.5\n",
    "            target_binary = target > 0.5\n",
    "            \n",
    "            # Dice score\n",
    "            intersection = (pred & target_binary).float().sum((1, 2, 3))\n",
    "            union = pred.float().sum((1, 2, 3)) + target_binary.float().sum((1, 2, 3))\n",
    "            dice = (2 * intersection) / (union + 1e-7)\n",
    "            dice_score += dice.mean().item()\n",
    "            \n",
    "            # IoU score\n",
    "            iou = intersection / (union - intersection + 1e-7)\n",
    "            iou_score += iou.mean().item()\n",
    "    \n",
    "    # Calculate averages\n",
    "    val_loss /= len(val_loader)\n",
    "    dice_score /= len(val_loader)\n",
    "    iou_score /= len(val_loader)\n",
    "    \n",
    "    return val_loss, dice_score, iou_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff24af7",
   "metadata": {},
   "source": [
    "## 7. Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracking metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "dice_scores = []\n",
    "iou_scores = []\n",
    "best_dice = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.epoch):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epoch}\")\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        x = batch['image'].to(config.device)\n",
    "        target = batch['label'].to(config.device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred0, pred1, pred2 = model(x)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss0 = structure_loss(pred0, target)\n",
    "        loss1 = structure_loss(pred1, target)\n",
    "        loss2 = structure_loss(pred2, target)\n",
    "        loss = loss0 + loss1 + loss2\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    epoch_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, dice_score, iou_score = validate(model, val_loader, config.device)\n",
    "    val_losses.append(val_loss)\n",
    "    dice_scores.append(dice_score)\n",
    "    iou_scores.append(iou_score)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{config.epoch}\")\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Dice Score: {dice_score:.4f}, IoU: {iou_score:.4f}\")\n",
    "    \n",
    "    # Save model if it has the best dice score\n",
    "    if dice_score > best_dice:\n",
    "        best_dice = dice_score\n",
    "        torch.save(model.state_dict(), os.path.join(config.save_path, 'SAM2-UNet-best.pth'))\n",
    "        print(f\"Saved new best model with Dice score: {best_dice:.4f}\")\n",
    "    \n",
    "    # Save checkpoint every 5 epochs or at the last epoch\n",
    "    if (epoch+1) % 5 == 0 or (epoch+1) == config.epoch:\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(config.save_path, f'SAM2-UNet-{epoch+1}.pth')\n",
    "        )\n",
    "        print(f\"Saved checkpoint: SAM2-UNet-{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc965b9",
   "metadata": {},
   "source": [
    "## 8. Plot Training and Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c880ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(dice_scores, label='Dice Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('Validation Dice Score')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(iou_scores, label='IoU Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('Validation IoU Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.save_path, 'training_metrics.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0daad51",
   "metadata": {},
   "source": [
    "## 9. Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set():\n",
    "    # Load best model for predictions\n",
    "    model.load_state_dict(torch.load(os.path.join(config.save_path, 'SAM2-UNet-best.pth')))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get all test images\n",
    "    test_images = sorted([f for f in os.listdir(config.test_image_path) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    \n",
    "    # Create test dataset loader\n",
    "    test_loader = TestDataset(\n",
    "        config.test_image_path,\n",
    "        config.image_size\n",
    "    )\n",
    "    \n",
    "    # Create prediction directory\n",
    "    prediction_dir = config.prediction_output_path\n",
    "    os.makedirs(prediction_dir, exist_ok=True)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(f\"Making predictions on {test_loader.size} test images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(test_loader.size)):\n",
    "            # Custom load_data for test set without ground truth\n",
    "            image, _, name = test_loader.load_data()\n",
    "            image = image.to(config.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            res, _, _ = model(image)\n",
    "            \n",
    "            # Convert to sigmoid probability and resize to original size\n",
    "            res = torch.sigmoid(res)\n",
    "            \n",
    "            # Convert to numpy and scale to [0, 255]\n",
    "            res = res.data.cpu().numpy().squeeze()\n",
    "            res = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
    "            res = (res * 255).astype(np.uint8)\n",
    "            \n",
    "            # Save prediction\n",
    "            Image.fromarray(res).save(os.path.join(prediction_dir, name[:-4] + \".png\"))\n",
    "            \n",
    "    print(f\"Predictions saved to {prediction_dir}\")\n",
    "\n",
    "# Run test predictions\n",
    "predict_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08881e76",
   "metadata": {},
   "source": [
    "## 10. Visualize Some Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions():\n",
    "    # Get some sample predictions (first 5)\n",
    "    prediction_dir = config.prediction_output_path\n",
    "    test_images = sorted([f for f in os.listdir(config.test_image_path) \n",
    "                        if f.endswith('.jpg') or f.endswith('.png')])[:5]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, img_name in enumerate(test_images):\n",
    "        # Original image\n",
    "        img_path = os.path.join(config.test_image_path, img_name)\n",
    "        image = np.array(Image.open(img_path))\n",
    "        \n",
    "        # Prediction mask\n",
    "        pred_path = os.path.join(prediction_dir, img_name[:-4] + \".png\")\n",
    "        if os.path.exists(pred_path):\n",
    "            pred = np.array(Image.open(pred_path))\n",
    "        else:\n",
    "            pred = np.zeros_like(image[:,:,0])\n",
    "            \n",
    "        # Plot original image\n",
    "        plt.subplot(5, 2, i*2+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Original: {img_name}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Plot prediction mask\n",
    "        plt.subplot(5, 2, i*2+2)\n",
    "        plt.imshow(pred, cmap='gray')\n",
    "        plt.title(f\"Prediction: {img_name[:-4]}.png\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(prediction_dir, 'sample_predictions.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde0eca",
   "metadata": {},
   "source": [
    "## 11. Prepare Submission for Kaggle (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_kaggle_submission():\n",
    "    \"\"\"\n",
    "    Create a submission file or zip folder for Kaggle, depending on the competition requirements\n",
    "    \"\"\"\n",
    "    prediction_dir = config.prediction_output_path\n",
    "    submission_path = 'submission_kaggle'\n",
    "    \n",
    "    # Create submission directory if it doesn't exist\n",
    "    os.makedirs(submission_path, exist_ok=True)\n",
    "    \n",
    "    # Copy prediction files to submission directory (you may need to adapt this based on competition requirements)\n",
    "    prediction_files = [f for f in os.listdir(prediction_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for file in tqdm(prediction_files, desc=\"Preparing submission\"):\n",
    "        shutil.copy(\n",
    "            os.path.join(prediction_dir, file),\n",
    "            os.path.join(submission_path, file)\n",
    "        )\n",
    "    \n",
    "    # Create a zip file if needed\n",
    "    shutil.make_archive('submission_kaggle', 'zip', submission_path)\n",
    "    \n",
    "    print(f\"Submission prepared: {len(prediction_files)} files\")\n",
    "    print(f\"Submission files in: {submission_path}/\")\n",
    "    print(f\"Submission zip: submission_kaggle.zip\")\n",
    "\n",
    "# Prepare submission\n",
    "prepare_kaggle_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b53e2c",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusion\n",
    "\n",
    "The SAM2-UNet model has been:\n",
    "1. Trained on the provided training data\n",
    "2. Validated using the validation data\n",
    "3. Used to generate predictions on the test data\n",
    "4. The predictions have been saved to a new folder for Kaggle submission\n",
    "\n",
    "Key metrics from training:\n",
    "- Best Validation Dice Score: {best_dice:.4f}\n",
    "- Best model saved to: {config.save_path}/SAM2-UNet-best.pth\n",
    "- Test predictions saved to: {config.prediction_output_path}\n",
    "- Kaggle submission prepared in: submission_kaggle.zip"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
